{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c101dda2-746d-4cb7-8410-4a57e25d751b",
   "metadata": {},
   "source": [
    "# Validating a classification model with Trubrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2758ff6-626f-4a5e-8643-61b81144cefe",
   "metadata": {},
   "source": [
    "In this tutorial of the [Titanic Use Case](https://www.kaggle.com/c/titanic), you will:\n",
    "- Initialise a `DataContext` with ML datasets and metadata from the titanic use case\n",
    "- Build some out-of-the-box validations on a trained model and the `DataContext` with the `ModelValidator`:\n",
    "    - Performance validations:\n",
    "        - With sklearn metrics\n",
    "        - With custom metrics\n",
    "        - On specific data sclices\n",
    "    - Explainability validations (with permutation importance)\n",
    "    - Minimum functionality validation\n",
    "    - Inference time validation\n",
    "- Build a custom **data validation**\n",
    "- Save validations to a `Trubric`\n",
    "- Execute the `Trubric` from file\n",
    "- Execute the `Trubric` from the CLI tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7c101-416b-4680-9dc9-99e2c6b554cf",
   "metadata": {},
   "source": [
    "## Install the trubrics-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690ac83-22ab-452d-8824-f6bc516df0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install trubrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249214ce-4183-480d-8bef-de29f8a0fd9a",
   "metadata": {},
   "source": [
    "## Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.example import get_titanic_data_and_model\n",
    "train_df, test_df, model = get_titanic_data_and_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d7ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Init DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e2c4-74bc-48f4-b766-2d1ccd8b5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.context import DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b70d3-6aff-4fa2-ba51-524ef4f25699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context = DataContext(\n",
    "    name=\"my_first_dataset\",\n",
    "    version=\"0.1\",\n",
    "    target=\"Survived\",\n",
    "    testing_data=test_df,\n",
    "    training_data=train_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b8997-3020-40f8-84f3-0a32bf18477b",
   "metadata": {},
   "source": [
    "## Init ModelValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99bba3-065b-47bb-8858-7df580b9e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich  # for pretty prints\n",
    "\n",
    "from trubrics.validations import ModelValidator\n",
    "from examples.classification_titanic.custom_scorer import custom_scorers  # see ./custom_scorer.py example\n",
    "from examples.classification_titanic.slicing_functions import slicing_functions  # see ./slicing_functions.py for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991339f-3318-4741-b0a1-8ab05533e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validator = ModelValidator(\n",
    "    data=data_context, model=model, custom_scorers=custom_scorers, slicing_functions=slicing_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586484c-a49c-4e25-bb09-8df9008a8d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the ModelValidator to build out-of-the-box validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90323425-1677-432e-a3c2-950565282e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance = [\n",
    "    # validate overall model performance with a manual threshold\n",
    "    model_validator.validate_performance_against_threshold(metric=\"recall\", threshold=0.7),\n",
    "\n",
    "    # validate model performance on a specific data slice\n",
    "    model_validator.validate_performance_against_threshold(metric=\"recall\", threshold=0.8, data_slice=\"children\"),\n",
    "\n",
    "    # validate model performance with a custom metric \"my_custom_loss\"\n",
    "    model_validator.validate_performance_against_threshold(metric=\"my_custom_loss\", threshold=-0.7),\n",
    "\n",
    "    # validate model performance difference between train and test sets (overfit)\n",
    "    model_validator.validate_performance_between_train_and_test(metric=\"recall\", threshold=0.3),\n",
    "\n",
    "    # validate model performance against an sklearn dummy model\n",
    "    model_validator.validate_test_performance_against_dummy(metric=\"accuracy\"),\n",
    "\n",
    "    # validate model performance is regular between various data slices\n",
    "    model_validator.validate_performance_std_across_slices(metric=\"accuracy\", std_threshold=0.07, dataset=\"testing_data\", data_slices=[\"male\", \"children\"]),\n",
    "]\n",
    "\n",
    "for performance_val in performance:\n",
    "    rich.print(performance_val.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68144d-70ef-438c-ba47-8141dbb7a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability = [\n",
    "    # validate that a feature is in the top N important features of permutation feature importances\n",
    "    model_validator.validate_feature_in_top_n_important_features(dataset=\"testing_data\", feature=\"Sex\", top_n_features=3),\n",
    "\n",
    "    # validate the top N features are the same in train and test sets (overfit)\n",
    "    model_validator.validate_feature_importance_between_train_and_test(top_n_features=2),\n",
    "]\n",
    "\n",
    "for explainability_val in explainability:\n",
    "    rich.print(explainability_val.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a147cd-78f6-4d58-93fb-5ec9c2a7d781",
   "metadata": {},
   "source": [
    "Check out the docs for many more [out-of-the-box validations](https://trubrics.github.io/trubrics-sdk/validations/), such as:\n",
    "- Test the inference time of your model\n",
    "- Test your model's minimum functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f59af-9cce-4017-89ad-e2b476285a13",
   "metadata": {},
   "source": [
    "## Build a custom validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e0bb3-b995-483b-ba5e-975271486ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.classification_titanic.custom_validator import CustomValidator  # see custom_validator.py for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1b64-6d66-44f5-955f-9fd75db8529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom_validator = CustomValidator(data=data_context, model=model, custom_scorers=custom_scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf10c3-2299-4cbb-860b-33e7b87208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = [\n",
    "    model_custom_validator.validate_master_age(age_limit_master=13, severity=\"warning\")\n",
    "]\n",
    "\n",
    "rich.print(custom[0].dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45ce41-d3f0-4e98-b638-7fb0ff817971",
   "metadata": {},
   "source": [
    "## Save validations as a trubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bdeea-c7bc-4833-b89c-c184f056045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import Trubric\n",
    "\n",
    "validations =  performance + explainability + custom\n",
    "\n",
    "trubric = Trubric(\n",
    "    name=\"model_validations\",\n",
    "    model_name=\"my_model\",\n",
    "    model_version=\"0.0.1\",\n",
    "    data_context_name=data_context.name,\n",
    "    data_context_version=data_context.version,\n",
    "    metadata={\"some parameter\": \"xyz\"},\n",
    "    tags=[\"mars-demo\"],\n",
    "    validations=validations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e0cd3-8c54-459c-b7db-3f0134f6faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trubric to a local .json\n",
    "trubric.save_local(path=\"./my_first_trubric.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29db54-3c01-4bf2-9fea-6ecd3e983023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or save to trubrics UI\n",
    "try:\n",
    "    trubric.save_ui()\n",
    "    print(\"Trubric saved to UI.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in saving to trubrics manager:\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d6ef0-c169-4d79-ad6e-8872539370fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute the trubric from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fed1d8-842b-4e07-ae49-9a6d13f3743e",
   "metadata": {},
   "source": [
    "The `TrubricRun` object allows you to pull in a Trubric from file, and run that directly against any model and DataContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64e984-872c-4d04-8573-5dd1295e0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations.run import TrubricRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4005f0b-9aaf-4ff9-bf66-2d3703ddd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "trubric_from_file = Trubric.parse_file(\"./my_first_trubric.json\")\n",
    "\n",
    "trubric_run_context = TrubricRun(\n",
    "    data_context=data_context,\n",
    "    model=model,\n",
    "    trubric=trubric_from_file,\n",
    "    tags=[\"dev\"],\n",
    "    custom_validator=CustomValidator,\n",
    "    custom_scorers=custom_scorers,\n",
    "    slicing_functions=slicing_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9188a70-7b06-4ac3-a191-cdace29e4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trubric = trubric_run_context.set_new_trubric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed711e-cc3a-4d2c-9575-e78d633c628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_trubric.save_local()  # save the new trubric\n",
    "# new_trubric.save_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da79f0-0d21-4adc-b674-f56f09809a49",
   "metadata": {},
   "source": [
    "## Execute a trubric from the CLI (our short CLI demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7bff0-1d97-4311-beb1-c4404e37dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! trubrics run \\\n",
    "  --no-save-ui \\\n",
    "  --run-context-path titanic-example-trubric \\\n",
    "  --trubric-output-file-path \"my_new_trubric.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1622fa-fe11-4d69-9ceb-590f660fe960",
   "metadata": {},
   "source": [
    "## Connection to the Trubrics platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74003a73-34c0-4710-9e5d-4cbb460b53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "os.environ[\"TRUBRICS_CONFIG_EMAIL\"] = input(\"Enter your Trubrics account email:\")\n",
    "os.environ[\"TRUBRICS_CONFIG_PASSWORD\"] = getpass.getpass(\"Enter your password:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e51d2-bb3b-4071-aed6-7c11f77d7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "! trubrics init --trubrics-user --project-name \"demo project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42a01d-5c4f-4ded-8000-660572bcb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! trubrics run \\\n",
    "  --save-ui \\\n",
    "  --run-context-path titanic-example-trubric \\\n",
    "  --trubric-output-file-path \"my_new_trubric.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37",
   "language": "python",
   "name": "venv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
