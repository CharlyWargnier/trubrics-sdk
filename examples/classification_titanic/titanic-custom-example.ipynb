{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7f4b84-923d-4be3-8715-73a2d50eabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install trubrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5da53-431b-4b76-8beb-be24bbfcef6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7730264d-82e8-4676-9ec1-b20d9e33b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.example import get_titanic_data_and_model\n",
    "titanic_dataset, _, model = get_titanic_data_and_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2b6fa-2653-4bf4-8a26-bb8e28f96152",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Init DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac49b41-71d3-4abc-9358-e1690ce04f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.context import DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c491f35a-519f-4171-b233-28b0f5378a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context = DataContext(\n",
    "    name=\"my_first_dataset\",\n",
    "    version=0.1,\n",
    "    testing_data=titanic_dataset,  # for assortment, this can just be your entire dataset\n",
    "    target=\"Survived\"  # for assortment this is your scoring column. If you have multiple scores to validate, you should create multiple data contexts. Create this column, even if it is full of zeros as you don't have a ground truth.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1a5d1-d0cd-44c2-a97c-d3e0dad8660b",
   "metadata": {},
   "source": [
    "## Custom model / algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38215c93-5a22-4099-8969-dc9e27ce8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleCustomModel:\n",
    "    \"\"\"\n",
    "    This is a custom model that scores passengers based on probability of survival.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self._estimator_type = \"regressor\"\n",
    "\n",
    "    def predict(self, df):\n",
    "        \"\"\"Scores of passengers, or probability that they will survive.\"\"\"\n",
    "        return self.model.predict_proba(df)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d31042-405f-4a82-bb63-4475bf119b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99      , 0.07      , 0.06733333, 0.07      , 0.98      ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example first 5 scores\n",
    "ExampleCustomModel(model=model).predict(data_context.X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3beddb17-4eac-49a5-8bb5-6e96455f0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = ExampleCustomModel(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c80010-227c-4001-8e5f-cdd340feae7a",
   "metadata": {},
   "source": [
    "## Build custom validations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d92bd-145e-4092-8ef1-5d2e3b8ebcbd",
   "metadata": {},
   "source": [
    "Lets build the following custom validations:\n",
    "\n",
    "**Data validations**\n",
    "- validate that passengers with the title \"master\" are younger than a certain age\n",
    "\n",
    "**Model validations**\n",
    "- validate that the model scores are on average higher for females than for males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972eee0b-8ba2-46c7-b0ef-c6d1ad5ab11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import ModelValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c16a3c85-1503-455e-9459-c31d1410ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations.validation_output import (\n",
    "    validation_output,\n",
    "    validation_output_type,\n",
    ")\n",
    "\n",
    "class CustomValidator(ModelValidator):\n",
    "    def __init__(self, data: DataContext, model, slicing_functions=None):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        \n",
    "    def _validate_master_age(self, age_limit_master):\n",
    "        master_df = self.data.testing_data.loc[lambda df: df[\"Title\"]==\"Master\"]\n",
    "        errors_df = master_df.loc[lambda df: df[\"Age\"] >= age_limit_master]\n",
    "        return len(errors_df) == 0, {\"errors_df\": errors_df.to_dict()}\n",
    "\n",
    "    @validation_output\n",
    "    def validate_master_age(self, age_limit_master: int, severity=None):\n",
    "        \"\"\"Validate that passengers with the title \"master\" are younger than a certain age\n",
    "\n",
    "        Args:\n",
    "            age_limit_master: cut off value for master\n",
    "\n",
    "        Returns:\n",
    "            True for success, false otherwise. With a results dictionary giving dict of errors.\n",
    "        \"\"\"\n",
    "        return self._validate_master_age(age_limit_master)\n",
    "    \n",
    "    def _validate_model_scores_females_higher(self):\n",
    "        predictions_df = self.data.testing_data.assign(predictions=self.model.predict(data_context.X_test))\n",
    "        def _average_score_sex(sex):\n",
    "            return round(predictions_df.loc[predictions_df[\"Sex\"]==sex, \"predictions\"].mean(), 3)\n",
    "        \n",
    "        score_female = _average_score_sex(sex=\"female\")\n",
    "        score_male = _average_score_sex(sex=\"male\")\n",
    "        return score_female > score_male, {\"score_female\": score_female, \"score_male\": score_male}\n",
    "    \n",
    "    @validation_output\n",
    "    def validate_model_scores_females_higher(self, severity=None):\n",
    "        \"\"\"We want the model to score female passengers with a higher probability of survival,\n",
    "        so we are validating the average scores are higher for females than for males.\n",
    "        \n",
    "        Returns:\n",
    "            True for success, false otherwise. With a results dictionary giving mean scores for both populations.\n",
    "        \"\"\"\n",
    "        return self._validate_model_scores_females_higher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070a446c-f843-4553-a04a-d3eba5994745",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = CustomValidator(data=data_context, model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa3b046-ffdc-4a9b-8ab4-1548d6cf0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "validations = [\n",
    "    validator.validate_master_age(age_limit_master=13),\n",
    "    validator.validate_model_scores_females_higher(severity=\"experiment\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247683f-799e-4e4d-812a-14c8699809cb",
   "metadata": {},
   "source": [
    "## Save validations as a trubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124bdeea-c7bc-4833-b89c-c184f056045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import Trubric\n",
    "\n",
    "trubric = Trubric(\n",
    "    trubric_name=\"my_first_trubric\",\n",
    "    model_name=\"my_model\",\n",
    "    model_version=0.1,\n",
    "    data_context_name=data_context.name,\n",
    "    data_context_version=data_context.version,\n",
    "    metadata={\"tag\": \"master\"}, # tag any metadata here\n",
    "    validations=validations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcda747-2567-4a0d-a486-15c36914655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 17:17:49.650 | INFO     | trubrics.validations.dataclass:save_local:107 - Trubric saved to my_first_trubric.json.\n"
     ]
    }
   ],
   "source": [
    "# save trubric to a local .json\n",
    "trubric.save_local(path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e3a15-da05-4c2d-ba74-0ef27bd1f461",
   "metadata": {},
   "source": [
    "## Run trubric from CICDCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12a31f-7b70-4eb7-b471-4340c9bda34b",
   "metadata": {},
   "source": [
    "The last step is to run the validations from the trubric .json against new data / models everytime there is any potential change. See our [CLI docs](https://trubrics.github.io/trubrics-sdk/trubrics_cli/) for info."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trubrics-venv",
   "language": "python",
   "name": "trubrics-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
