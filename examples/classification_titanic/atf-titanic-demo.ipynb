{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6c656-5936-4f9b-baf3-195aa59f2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trubrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2758ff6-626f-4a5e-8643-61b81144cefe",
   "metadata": {},
   "source": [
    "**In this tutorial of the [Titanic Use Case](https://www.kaggle.com/c/titanic), you will:**\n",
    "- Initialise a `DataContext` with ML datasets and metadata from the titanic use case\n",
    "- Build some out-of-the-box validations on a trained model and the `DataContext` with the `ModelValidator`:\n",
    "    - Minimum functionality validation\n",
    "    - Performance validations:\n",
    "        - With sklearn metrics\n",
    "        - With custom metrics\n",
    "    - Explainability validation (with permutation importance)\n",
    "    - Inference time validation\n",
    "- Example of how feedback can be used to create meaningful validations\n",
    "- Build a custom validation\n",
    "- Save validations to a `Trubric`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249214ce-4183-480d-8bef-de29f8a0fd9a",
   "metadata": {},
   "source": [
    "## Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.example import get_titanic_data_and_model\n",
    "train_df, test_df, model = get_titanic_data_and_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d7ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Init DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e2c4-74bc-48f4-b766-2d1ccd8b5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.context import DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b70d3-6aff-4fa2-ba51-524ef4f25699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context = DataContext(\n",
    "    name=\"my_first_dataset\",\n",
    "    version=0.1,\n",
    "    testing_data=test_df,\n",
    "    target=\"Survived\",\n",
    "    training_data=train_df,\n",
    "    minimum_functionality_data=test_df.head(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b8997-3020-40f8-84f3-0a32bf18477b",
   "metadata": {},
   "source": [
    "## Init ModelValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99bba3-065b-47bb-8858-7df580b9e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import ModelValidator\n",
    "from examples.classification_titanic.custom_scorer import custom_scorers  # see .py script for custom_scorer example\n",
    "from examples.classification_titanic.slicing_functions import slicing_functions  # see .py script for slicing_functions examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991339f-3318-4741-b0a1-8ab05533e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validator = ModelValidator(\n",
    "    data=data_context, model=model, custom_scorers=custom_scorers, slicing_functions=slicing_functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586484c-a49c-4e25-bb09-8df9008a8d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the ModelValidator to build out-of-the-box validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa688-2622-49c3-8ee7-827b66362fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "minimum_functionality = [\n",
    "    model_validator.validate_minimum_functionality(severity=\"warning\"),  # validation severity can be passed in to any validation\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in minimum_functionality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90323425-1677-432e-a3c2-950565282e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance = [\n",
    "    model_validator.validate_performance_against_threshold(metric=\"my_custom_loss\", threshold=-0.7, severity=\"experiment\"),\n",
    "    model_validator.validate_performance_between_train_and_test(metric=\"my_custom_loss\", threshold=0.2),\n",
    "    model_validator.validate_performance_std_across_slices(metric=\"accuracy\", dataset=\"testing_data\", data_slices=[\"male\", \"children\"], std_threshold=0.07),\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68144d-70ef-438c-ba47-8141dbb7a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability = [\n",
    "    model_validator.validate_feature_in_top_n_important_features(dataset=\"testing_data\", feature=\"Sex\", top_n_features=3),\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in explainability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0cc18-de1a-44ca-a48e-9f5bb518f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# recap of calculated model performance metrics by validations\n",
    "pd.DataFrame(model_validator.performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f59af-9cce-4017-89ad-e2b476285a13",
   "metadata": {},
   "source": [
    "## Build custom validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e0bb3-b995-483b-ba5e-975271486ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.classification_titanic.custom_validator import CustomValidator  # see script for CustomValidator example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1b64-6d66-44f5-955f-9fd75db8529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom_validator = CustomValidator(data=data_context, model=model, custom_scorers=custom_scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf10c3-2299-4cbb-860b-33e7b87208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = [model_custom_validator.validate_performance_for_different_fares(fare_cutoff=25, severity=\"warning\")]\n",
    "_ = [rich.print(val.dict()) for val in custom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45ce41-d3f0-4e98-b638-7fb0ff817971",
   "metadata": {},
   "source": [
    "## Save validations as a trubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bdeea-c7bc-4833-b89c-c184f056045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import Trubric\n",
    "\n",
    "validations = minimum_functionality + performance + explainability + custom\n",
    "\n",
    "trubric = Trubric(\n",
    "    trubric_name=\"my_first_trubric\",\n",
    "    model_name=\"my_model\",\n",
    "    data_context_name=data_context.name,\n",
    "    data_context_version=data_context.version,\n",
    "    metadata={\"tag\": \"master\"},\n",
    "    validations=validations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e0cd3-8c54-459c-b7db-3f0134f6faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trubric to a local .json\n",
    "trubric.save_local(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76277498-9ce8-4643-8c55-2cd4c313d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat my_first_trubric.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da79f0-0d21-4adc-b674-f56f09809a49",
   "metadata": {},
   "source": [
    "## Execute the trubric from the CLI tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dd51f-624c-4786-a7df-d221f847b61d",
   "metadata": {},
   "source": [
    "Example code snippet:\n",
    "\n",
    "```bash\n",
    "(venv)$ trubrics run \\\n",
    "        --trubric-config-path \"examples/classification_titanic\" \\\n",
    "        --trubric-output-file-path \"examples/classification_titanic\" \\\n",
    "        --trubric-output-file-name \"my_new_trubric.json\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trubrics-venv",
   "language": "python",
   "name": "trubrics-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
