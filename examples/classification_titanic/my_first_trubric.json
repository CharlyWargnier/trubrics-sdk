{
    "name": "my_first_trubric",
    "model_name": "my_model",
    "model_version": 0.1,
    "data_context_name": "my_first_dataset",
    "data_context_version": 0.1,
    "metadata": {
        "tag": "master"
    },
    "validations": [
        {
            "validation_type": "validate_performance_against_threshold",
            "validation_kwargs": {
                "args": [],
                "kwargs": {
                    "metric": "precision",
                    "threshold": 0.7
                }
            },
            "explanation": "**Performance validation versus a fixed threshold value.**\n\nCompares performance of a model on any of the datasets in the DataContext to a hard coded threshold value.\n\nExample:\n```py\nfrom trubrics.validations import ModelValidator\nmodel_validator = ModelValidator(data=data_context, model=model)\nmodel_validator.validate_performance_against_threshold(\nmetric=\"recall\",\nthreshold=0.8\n)\n```\n\nArgs:\nmetric: performance metric name defined in sklearn (sklearn.metrics.SCORERS) or in a custom scorer fed in when initialising the ModelValidator object.\nthreshold: the performance threshold that the model must attain.\ndataset: the name of a dataset from the DataContext {'testing_data', 'training_data'}.\ndata_slice: the name of the data slice, specified in the slicing_functions parameter of ModelValidator.\nseverity: severity of the validation. Can be either {'error', 'warning', 'experiment'}. If None, defaults to 'error'.\n\nReturns:\nTrue for success, false otherwise. With a results dictionary giving the actual model performance calculated.\n",
            "outcome": "pass",
            "severity": "error",
            "result": {
                "performance": 0.7047619047619048,
                "sample_size": 295
            }
        },
        {
            "validation_type": "validate_performance_against_threshold",
            "validation_kwargs": {
                "args": [],
                "kwargs": {
                    "metric": "f1",
                    "threshold": 0.7
                }
            },
            "explanation": "**Performance validation versus a fixed threshold value.**\n\nCompares performance of a model on any of the datasets in the DataContext to a hard coded threshold value.\n\nExample:\n```py\nfrom trubrics.validations import ModelValidator\nmodel_validator = ModelValidator(data=data_context, model=model)\nmodel_validator.validate_performance_against_threshold(\nmetric=\"recall\",\nthreshold=0.8\n)\n```\n\nArgs:\nmetric: performance metric name defined in sklearn (sklearn.metrics.SCORERS) or in a custom scorer fed in when initialising the ModelValidator object.\nthreshold: the performance threshold that the model must attain.\ndataset: the name of a dataset from the DataContext {'testing_data', 'training_data'}.\ndata_slice: the name of the data slice, specified in the slicing_functions parameter of ModelValidator.\nseverity: severity of the validation. Can be either {'error', 'warning', 'experiment'}. If None, defaults to 'error'.\n\nReturns:\nTrue for success, false otherwise. With a results dictionary giving the actual model performance calculated.\n",
            "outcome": "pass",
            "severity": "error",
            "result": {
                "performance": 0.7115384615384616,
                "sample_size": 295
            }
        },
        {
            "validation_type": "validate_master_age",
            "validation_kwargs": {
                "args": [],
                "kwargs": {
                    "age_limit_master": 13
                }
            },
            "explanation": "Validate that passengers with the title \"master\" are younger than a certain age\n\nArgs:\nage_limit_master: cut off value for master\n\nReturns:\nTrue for success, false otherwise. With a results dictionary giving dict of errors.\n",
            "outcome": "pass",
            "severity": "warning",
            "result": {
                "errors_df": {
                    "Sex": {},
                    "Embarked": {},
                    "Title": {},
                    "Pclass": {},
                    "Age": {},
                    "SibSp": {},
                    "Parch": {},
                    "Fare": {},
                    "Survived": {}
                }
            }
        }
    ]
}