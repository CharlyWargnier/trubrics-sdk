{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a30678-583c-4d85-9cf4-a691a84aaa77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "relative_root = \"../..\"\n",
    "sys.path.append(relative_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b47bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import rich\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from examples.training import titanic_config\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249214ce-4183-480d-8bef-de29f8a0fd9a",
   "metadata": {},
   "source": [
    "## Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    preprocessed_train = pd.read_csv(Path(relative_root) / titanic_config.LOCAL_TRAIN_FILENAME)\n",
    "    preprocessed_test = pd.read_csv(Path(relative_root) / titanic_config.LOCAL_TEST_FILENAME)\n",
    "    rf_model = joblib.load(Path(relative_root) / titanic_config.LOCAL_MODEL_FILENAME)\n",
    "    with open(Path(relative_root) / titanic_config.LOCAL_FI_FILENAME, \"r\") as file:\n",
    "        feature_importance = json.loads(file.read())\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"To generate these files, run `make train-titanic`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e26e96-2e3a-44fe-8894-69e20b244c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.predict(preprocessed_test)[0]  # test model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d7ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Init trubrics context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e2c4-74bc-48f4-b766-2d1ccd8b5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.context import DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b70d3-6aff-4fa2-ba51-524ef4f25699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context = DataContext(\n",
    "    name=\"my_first_dataset\",\n",
    "    version=0.1,\n",
    "    training_data=preprocessed_train,\n",
    "    testing_data=preprocessed_test,\n",
    "    target_column=titanic_config.TARGET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b8997-3020-40f8-84f3-0a32bf18477b",
   "metadata": {},
   "source": [
    "## Init trubrics validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99bba3-065b-47bb-8858-7df580b9e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations import ModelValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233de65a-b70f-4c85-9258-fb7f78ff6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "rich.print(\"Choose error metric from sklearn defaults: \", list(sklearn.metrics.SCORERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991339f-3318-4741-b0a1-8ab05533e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validator = ModelValidator(metric=\"accuracy\", data=data_context, model=rf_model)\n",
    "rich.print(f\"Test set {model_validator.metric} score\", model_validator.score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586484c-a49c-4e25-bb09-8df9008a8d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the trubrics validator to create out-of-the-box validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76440fef-3b53-4b58-8a61-faef07b48207",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_case = {\n",
    "    \"Sex\": \"male\",\n",
    "    \"Embarked\": \"S\",\n",
    "    \"Title\": \"Master\",\n",
    "    \"Pclass\": 2,\n",
    "    \"Age\": 28,\n",
    "    \"SibSp\": 0,\n",
    "    \"Parch\": 0,\n",
    "    \"Fare\": 37\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa688-2622-49c3-8ee7-827b66362fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = [\n",
    "    model_validator.validate_single_edge_case(edge_case_data=edge_case, desired_output=0), # example of fail\n",
    "    model_validator.validate_single_edge_case(edge_case_data=edge_case, desired_output=1) # example of pass\n",
    "]\n",
    "robustness[0].severity = \"warning\"  # change the severity of a validation\n",
    "robustness[1].severity = \"experiment\"\n",
    "\n",
    "_ = [rich.print(val.dict()) for val in robustness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90323425-1677-432e-a3c2-950565282e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = [\n",
    "    model_validator.validate_performance_against_threshold(threshold=0.8),\n",
    "    model_validator.validate_performance_against_threshold(threshold=0.75),\n",
    "    model_validator.validate_performance_against_dummy(),\n",
    "    model_validator.validate_performance_against_dummy(strategy=\"stratified\"),\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641f5c1-8978-4866-83a0-ac40c69f75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness = [\n",
    "    model_validator.validate_biased_performance_across_category(category=\"Embarked\", threshold=0.1),\n",
    "    model_validator.validate_biased_performance_across_category(category=\"Sex\", threshold=0.05)\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in fairness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68144d-70ef-438c-ba47-8141dbb7a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability = [\n",
    "    model_validator.validate_feature_in_top_n_important_features(feature=\"Sex_female\", feature_importance=feature_importance, top_n_features=3),\n",
    "    model_validator.validate_feature_in_top_n_important_features(feature=\"Age\", feature_importance=feature_importance, top_n_features=2)\n",
    "]\n",
    "_ = [rich.print(val.dict()) for val in explainability]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4d137-430b-400d-b77c-6dff3f4ef190",
   "metadata": {},
   "source": [
    "## Collect user feedback from app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20239fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.utils.loader import get_business_feedback_data\n",
    "# read test data and run single outlier test\n",
    "try:\n",
    "    data = get_business_feedback_data(tracking=False)\n",
    "    display(data)\n",
    "except FileNotFoundError:\n",
    "    print(\"Please generate feedback from the streamlit app in order to read it back here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4840809-38fe-4da0-a6a7-dcdc8ab920e2",
   "metadata": {},
   "source": [
    "--> **DS response: \"It isn't normal, the model should not be more accurate for different groups of people. I'll add a test for this.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f59af-9cce-4017-89ad-e2b476285a13",
   "metadata": {},
   "source": [
    "## Create custom validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e0bb3-b995-483b-ba5e-975271486ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations.validation_output import validation_output, validation_output_type\n",
    "\n",
    "\n",
    "class CustomValidator(ModelValidator):\n",
    "    def __init__(self, data: DataContext, model, metric: str):\n",
    "        super().__init__(data, model, metric)\n",
    "        \n",
    "    @validation_output\n",
    "    def validate_performance_for_different_fares(self, fare_cutoff):\n",
    "        return self._validate_performance_for_different_fares(fare_cutoff)\n",
    "\n",
    "    def _validate_performance_for_different_fares(self, fare_cutoff: int = 50) -> validation_output_type:\n",
    "        \"\"\"\n",
    "        Write your custom validation function here.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "            This method is separated from validate_performance_for_different_fares\n",
    "            to apply @validation_output and for unit testing.\n",
    "\n",
    "            The @validation_output decorator allows you to generate a Validation object,\n",
    "            and must be used to be able to save your validation as part of a Trubric.\n",
    "            This decorator requires you to return values with the same type as validation_output_type.\n",
    "        \"\"\"\n",
    "        \n",
    "        errors_df = self.trubrics_model.testing_data_errors\n",
    "        number_of_errors_by_fare_ratio = (\n",
    "            errors_df.loc[lambda x: x[\"Fare\"] <= fare_cutoff].shape[0]\n",
    "            / errors_df.loc[lambda x: x[\"Fare\"] > fare_cutoff].shape[0]\n",
    "        )\n",
    "        return (\n",
    "            number_of_errors_by_fare_ratio > 0.5 and number_of_errors_by_fare_ratio < 1.5,\n",
    "            {\"number_of_errors_by_fare_ratio\": round(number_of_errors_by_fare_ratio, 3)}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1b64-6d66-44f5-955f-9fd75db8529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom_validator = CustomValidator(data=data_context, model=rf_model, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf10c3-2299-4cbb-860b-33e7b87208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = [model_custom_validator.validate_performance_for_different_fares(fare_cutoff=25)]\n",
    "custom[0].severity = \"warning\"  # change the severity of a validation\n",
    "_ = [rich.print(val.dict()) for val in custom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45ce41-d3f0-4e98-b638-7fb0ff817971",
   "metadata": {},
   "source": [
    "## Save trubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bdeea-c7bc-4833-b89c-c184f056045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.context import TrubricContext\n",
    "\n",
    "validations = robustness + performance + fairness + explainability + custom\n",
    "\n",
    "trubric_context = TrubricContext(\n",
    "    trubric_name=\"my_first_trubric\",\n",
    "    metric=model_validator.metric,\n",
    "    model_name=\"my_model\",\n",
    "    data_context_name=data_context.name,\n",
    "    data_context_version=data_context.version,\n",
    "    metadata={\"tag\": \"master\"},\n",
    "    validations=validations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e0cd3-8c54-459c-b7db-3f0134f6faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trubric to a local .json\n",
    "trubric_context.save_local(path=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018784d0-8dfb-468a-bdf2-f5644c92ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or save to trubrics UI\n",
    "user_id = None  # enter User ID from trubrics manager here\n",
    "url = None  # enter api url for trubrics manager here\n",
    "\n",
    "try:\n",
    "    trubric_context.save_ui(url=url, user_id=user_id)\n",
    "    print(\"Trubric saved to UI.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in saving to trubrics manager:\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d6ef0-c169-4d79-ad6e-8872539370fa",
   "metadata": {},
   "source": [
    "## Execute trubric from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64e984-872c-4d04-8573-5dd1295e0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trubrics.validations.run import run_trubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4005f0b-9aaf-4ff9-bf66-2d3703ddd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "trubric = TrubricContext.parse_file(\"../data/my_first_trubric.json\")\n",
    "\n",
    "all_validation_results = run_trubric(\n",
    "    data_context=data_context,\n",
    "    model=rf_model,\n",
    "    custom_validator=CustomValidator,\n",
    "    trubric=trubric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9188a70-7b06-4ac3-a191-cdace29e4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for validation_result in all_validation_results:\n",
    "    rich.print(f\"{validation_result.validation_type} - {validation_result.severity.upper()}.......{validation_result.outcome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7bff0-1d97-4311-beb1-c4404e37dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or run from cli\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "!make example-run-trubric \n",
    "os.chdir(\"examples/notebooks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trubrics-venv",
   "language": "python",
   "name": "trubrics-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
