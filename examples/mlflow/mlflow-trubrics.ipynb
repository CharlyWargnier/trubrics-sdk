{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd6f46-9f03-4e14-a760-bcb991f94e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940975a-6814-40cd-8667-ed3ac042dcee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.models.evaluation.base.list_evaluators()  # show installed evaluators. Should be ['default', 'trubrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f095321-068a-44ff-9c21-2dfcb4ca3db1",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619527c8-c3e4-4794-8629-9b38be8ba3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load UCI Adult dataset\n",
    "X, y = shap.datasets.adult()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "# train a boosting classifier\n",
    "model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "# set an evaluation dataset\n",
    "eval_data = X_test\n",
    "eval_data[\"label\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad1b1d-f40e-4ea2-857e-f023e8331682",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save to mlflow with Trubrics validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2746e-71ba-421c-a64c-7fbd4658d6ba",
   "metadata": {},
   "source": [
    "### Getting started with Trubrics evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbcec1-f78c-4317-9881-d6b9db9d17c8",
   "metadata": {},
   "source": [
    "To get started with the Trubrics evaluator plugin, you need two parameters in the `evaluator_config`:\n",
    "- **trubrics_path**: a Trubric file of validations (see below on how to build validations with Trubrics and save this file)\n",
    "- **model**: your ML model (see [compatible models](https://trubrics.github.io/trubrics-sdk/models/) with Trubrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053b6d0-a567-44a6-973a-ae2e57990233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model_uri = mlflow.sklearn.log_model(model, \"sklearn_model\").model_uri\n",
    "\n",
    "    mlflow.evaluate(\n",
    "        model=model_uri,\n",
    "        model_type=\"classifier\",\n",
    "        data=eval_data,\n",
    "        targets=\"label\",\n",
    "        evaluators=\"trubrics\",\n",
    "        evaluator_config={\"trubric_path\": \"./my_first_trubric.json\", \"model\": model}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b45e4-8f1d-4421-98ac-3f6bf3b2ce9d",
   "metadata": {},
   "source": [
    "**To see your mlflow run, open a terminal and execute:**\n",
    "```\n",
    "(venv)$ mlflow ui\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5182a6-af20-4da5-8b44-132de8ab1205",
   "metadata": {},
   "source": [
    "### Advanced usage of Trubrics evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58631a71-4893-4fbf-b109-923e1be0315b",
   "metadata": {},
   "source": [
    "For a more advanced example of how you can customise the Trubrics evaluator, we add more parameters into the `evaluator_config`:\n",
    "- **data_context**: specifying a `data_context` allows users to build validations on not just evaluation data, but also on your training data. This can be useful for validating if your model is overfitting, or if your training data and testing data follow similar distributions for example. See our [DataContext docs](https://trubrics.github.io/trubrics-sdk/data_context/) for more info.\n",
    "- **failing_severity**: this allows you to change the severity that you would like the Trubric to fail on. Setting `failing_severity=\"warning\"` means that any validation failure with a severity of \"warning\" or \"error\" will result in an overall failure of the Trubric and will raise an exception. The default behaviour is `failing_severity=\"error\"`, meaning only validation failures with `severity=\"error\"` will raise an exception.\n",
    "- **tags**: any tags that you want to save to your Trubric (separate from MLFlow tags).\n",
    "- **slicing_functions**: slicing functions in Trubrics allow you to validate your model performance on different data slices. See more [here](https://trubrics.github.io/trubrics-sdk/metrics/#3-data-slicing-functions).\n",
    "\n",
    "To unlock the full power of Trubrics, you should look at building custom validations for your model. Read more about this [here](https://trubrics.github.io/trubrics-sdk/custom_validations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e148d-5144-4a05-a7c3-2eeeca9771cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def age_young(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.loc[df[\"Age\"] < 25, :]\n",
    "\n",
    "slicing_functions = {\"young_adults\": age_young}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b31ea4-5531-4ae5-84f1-ff838c35d9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trubrics.context import DataContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e037e5f-09c0-41db-aa0d-102e208597ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model_uri = mlflow.sklearn.log_model(model, \"sklearn_model\").model_uri\n",
    "\n",
    "    mlflow.evaluate(\n",
    "        model=model_uri,\n",
    "        model_type=\"classifier\",\n",
    "        data=eval_data,\n",
    "        targets=\"label\",\n",
    "        evaluators=\"trubrics\",\n",
    "        evaluator_config={\n",
    "            \"trubric_path\": \"./my_second_trubric.json\",\n",
    "            \"model\": model,\n",
    "            \"data_context\": DataContext(name=\"mlflow-demo-data\", target=\"label\", testing_data=eval_data),\n",
    "            \"failing_severity\": \"warning\",\n",
    "            \"tags\": [\"mlflow-demo-tag\"],\n",
    "            \"slicing_functions\": slicing_functions   \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517c8be-0dc4-4cd7-8e94-1672f5671403",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build validations with Trubrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5cda4-c95a-475d-bc0b-a3777d2c391b",
   "metadata": {},
   "source": [
    "Here we'll see how we can build some simple validations for our model. For more info on building validations, you can view our full tutorial [here](https://colab.research.google.com/github/trubrics/trubrics-sdk/blob/main/examples/classification_titanic/classification_full_demo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc0715-c925-4e9a-8a71-e934cc57901a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rich\n",
    "\n",
    "from trubrics.context import DataContext\n",
    "from trubrics.validations import ModelValidator, Trubric\n",
    "data_context = DataContext(\n",
    "    target=\"label\", testing_data=eval_data\n",
    ")\n",
    "model_validator = ModelValidator(data=data_context, model=model)\n",
    "validations = [\n",
    "    model_validator.validate_performance_against_threshold(metric=\"accuracy\", threshold=0.8),\n",
    "    model_validator.validate_performance_against_threshold(metric=\"recall\", threshold=0.61, severity=\"warning\"),\n",
    "]\n",
    "\n",
    "#rich.print(validations[0], validations[1])\n",
    "\n",
    "trubric = Trubric(\n",
    "    name=\"mlflow-demo\",\n",
    "    data_context_name=data_context.name,\n",
    "    data_context_version=data_context.version,\n",
    "    validations=validations\n",
    ")\n",
    "\n",
    "#trubric.save_local(path=\"./my_first_trubric.json\")\n",
    "rich.print(trubric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac788e08-c42b-45e2-8363-17ba417266ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "venv39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
